{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d67456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 16:36:26.112860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 16:36:26.334506: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-25 16:36:26.339090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-25 16:36:26.339110: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-25 16:36:36.623193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-25 16:36:36.623312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-25 16:36:36.623322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from image_graph_util import img_conversion_v7\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from emnist import extract_training_samples,extract_test_samples\n",
    "from emnist import list_datasets\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34e611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img_conversion_v7.image_convert()\n",
    "\n",
    "\n",
    "patch=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fe027b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 16:37:00.430406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /data/user/home/nvekariy/.local/lib/python3.9/site-packages/cv2/../../lib64:/cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-25 16:37:00.430448: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-25 16:37:00.430477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0191): /proc/driver/nvidia/version does not exist\n",
      "2023-07-25 16:37:00.431077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ds, info = tfds.load('malaria', split='train', shuffle_files=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f376e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for example in ds:\n",
    "    train_images.append(example['image'].numpy())\n",
    "    train_labels.append(example['label'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b95fbb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27558\n",
      "27558\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2247515",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array([cv2.resize(i,(100,100), interpolation= cv2.INTER_CUBIC) for i in train_images])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918a0925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = [i/255 for i in images]\n",
    "labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79930fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(images,dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46338490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27558, 100, 100, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7b05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,train_lab,test_lab=train_test_split(images,labels,test_size=0.30,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1001252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19290, 100, 100, 3)\n",
      "(8268, 100, 100, 3)\n",
      "(19290,)\n",
      "(8268,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_lab.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375aa7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_train=train\n",
    "reg_train_label=train_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd49a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_val,regular_test,reg_val_label,reg_test_label=train_test_split(test,test_lab,test_size=0.50,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2010414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19290, 100, 100, 3)\n",
      "(4134, 100, 100, 3)\n",
      "(4134, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(regular_train.shape)\n",
    "print(regular_val.shape)\n",
    "print(regular_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60839dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#print((Counter(y_val)))\n",
    "print(np.sort(list(Counter(reg_train_label).keys())))\n",
    "classes=len(np.sort(list(Counter(reg_train_label).keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fce784",
   "metadata": {},
   "source": [
    "# Gershgorien image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d54c8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "\n",
    "def compute_lap_to_gersh(df_in): #compute_lap_to_gersh\n",
    "    adj_ary=np.ones(reg_train_patch.shape[-2]*reg_train_patch.shape[-1])-np.eye(reg_train_patch.shape[-2]*reg_train_patch.shape[-1])\n",
    "\n",
    "    gersh_c=np.tile(np.sum(adj_ary,axis=0),(reg_train_patch.shape[1],reg_train_patch.shape[2]))\n",
    "\n",
    "    edge=np.array(np.where(adj_ary==1))\n",
    "    ed0=edge[0]\n",
    "    ed1=edge[1]\n",
    "    no_img,no_ch, no_patch,patch_x,patch_y=df_in.shape\n",
    "    temp=[]\n",
    "    for i in range(no_img):\n",
    "        i_ary = np.eye(patch_x*patch_y)\n",
    "        i_ary4d=i_ary[np.newaxis,np.newaxis,:,:]\n",
    "        weighted_adj=np.zeros((no_ch, no_patch,patch_x*patch_y,patch_x*patch_y))\n",
    "        df=df_in[i].reshape(no_ch,no_patch,-1)\n",
    "        pixel1=df[:,:,ed0]\n",
    "        pixel2=df[:,:,ed1]  \n",
    "        edu_distance=np.sqrt((pixel1-pixel2)**2)+ 10**(-8)\n",
    "        weighted_adj[:,:,ed0,ed1]=edu_distance\n",
    "        sum_r=np.sum(weighted_adj,axis=2)\n",
    "        gersh_r=sum_r.reshape(no_ch,-1)\n",
    "        gersh_total=np.vstack((gersh_r[0],gersh_c[0],gersh_r[1],gersh_c[1],gersh_r[2],gersh_c[2]))\n",
    "        gersh_total=gersh_total.reshape(no_ch,2,gersh_c.shape[-1])\n",
    "        temp.append(gersh_total)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23a5b835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 4134  \r"
     ]
    }
   ],
   "source": [
    "reg_train_patch=img.to_patcharray(regular_train[:],patch_size=(patch,patch))\n",
    "reg_val_patch=img.to_patcharray(regular_val[:],patch_size=(patch,patch))\n",
    "reg_test_patch=img.to_patcharray(regular_test[:],patch_size=(patch,patch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "576f8299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19290, 3, 2500, 2, 2)\n",
      "(4134, 3, 2500, 2, 2)\n",
      "(4134, 3, 2500, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(reg_train_patch.shape)\n",
    "print(reg_val_patch.shape)\n",
    "print(reg_test_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b82bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 48\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Number of CPU cores:\", num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d889e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patch1=np.array_split(reg_train_patch[:], num_cores)\n",
    "val_patch1=np.array_split(reg_val_patch[:], num_cores)\n",
    "test_patch1=np.array_split(reg_test_patch[:], num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cd53696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(train_patch1))\n",
    "print(len(val_patch1))\n",
    "print(len(test_patch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcebb481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool:\n",
    "        # Define a list of numbers\n",
    "    train_p = train_patch1\n",
    "    \n",
    "        # Apply the square function to each number using the pool\n",
    "    g_train=pool.map(compute_lap_to_gersh,train_p)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    \n",
    "        #results = pool.map(calculate_visibility, numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca244dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=[]\n",
    "for submatrix in g_train:\n",
    "    temp1.extend(submatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d087f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gersh_train= np.array([np.asarray(submatrix) for submatrix in temp1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c43ee537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool1:\n",
    "        # Define a list of numbers\n",
    "    val_p = val_patch1\n",
    "    \n",
    "        # Apply the square function to each number using the pool\n",
    "    g_val=pool1.map(compute_lap_to_gersh,val_patch1)    \n",
    "    pool1.close()\n",
    "    pool1.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d66c6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2=[]\n",
    "for submatrix in g_val:\n",
    "    temp2.extend(submatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8950a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gersh_val= np.array([np.asarray(submatrix) for submatrix in temp2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e65520e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool2:\n",
    "        # Define a list of numbers\n",
    "    test_p = test_patch1\n",
    "    \n",
    "        # Apply the square function to each number using the pool\n",
    "    g_test=pool2.map(compute_lap_to_gersh,test_patch1) \n",
    "    pool2.close()\n",
    "    pool2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4128788",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3=[]\n",
    "for submatrix in g_test:\n",
    "    temp3.extend(submatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8083ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gersh_test= np.array([np.asarray(submatrix) for submatrix in temp3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b348698",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gersh_train=np.array(img1.to_gridlaparray(train_patch))\n",
    "gersh_val=np.array(img1.to_gridlaparray(val_patch))\n",
    "gersh_test=np.array(img1.to_gridlaparray(test_patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "089c2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19290, 3, 2, 10000)\n",
      "(4134, 3, 2, 10000)\n",
      "(4134, 3, 2, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(gersh_train.shape)\n",
    "print(gersh_val.shape)\n",
    "print(gersh_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc298dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgersh_train=gersh_train.reshape(reg_train_patch.shape[0],2,reg_train_patch.shape[-3]*reg_train_patch.shape[-2]*reg_train_patch.shape[-1],reg_train_patch.shape[1])\n",
    "rgersh_val=gersh_val.reshape(reg_val_patch.shape[0],2,reg_train_patch.shape[-3]*reg_train_patch.shape[-2]*reg_train_patch.shape[-1],reg_train_patch.shape[1])\n",
    "rgersh_test=gersh_test.reshape(reg_test_patch.shape[0],2,reg_train_patch.shape[-3]*reg_train_patch.shape[-2]*reg_train_patch.shape[-1],reg_train_patch.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aca0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19290, 2, 10000, 3)\n",
      "(4134, 2, 10000, 3)\n",
      "(4134, 2, 10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(rgersh_train.shape)\n",
    "print(rgersh_val.shape)\n",
    "print(rgersh_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603eaf1",
   "metadata": {},
   "source": [
    "# Gershgorien 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40e80720",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (rgersh_train.shape[1],rgersh_train.shape[2],rgersh_train.shape[3])\n",
    "num_classes = classes\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Conv2D(filters= 32, kernel_size=(1,3), activation='relu',padding='same',input_shape= input_shape))\n",
    "model3.add(tf.keras.layers.AveragePooling2D(pool_size=(1, 2),strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3),padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.AveragePooling2D(pool_size=(1, 2),strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3),padding='same',activation='relu'))\n",
    "model3.add(tf.keras.layers.AveragePooling2D(pool_size=(1, 2),strides=None,padding='valid'))\n",
    "\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "model3.add(tf.keras.layers.Dropout(0.1))\n",
    "model3.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19e88ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 2, 10000, 32)      320       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 2, 5000, 32)      0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 5000, 32)       3104      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 2, 2500, 32)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2500, 32)       3104      \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 2, 1250, 32)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               40960512  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,230,722\n",
      "Trainable params: 41,230,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee97382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41d9b7ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "603/603 [==============================] - 56s 91ms/step - loss: 0.5431 - acc: 0.7880 - val_loss: 0.1935 - val_acc: 0.9306\n",
      "Epoch 2/10\n",
      "603/603 [==============================] - 61s 102ms/step - loss: 0.1860 - acc: 0.9344 - val_loss: 0.1842 - val_acc: 0.9393\n",
      "Epoch 3/10\n",
      "603/603 [==============================] - 67s 112ms/step - loss: 0.1285 - acc: 0.9571 - val_loss: 0.1934 - val_acc: 0.9381\n",
      "Epoch 4/10\n",
      "603/603 [==============================] - 69s 115ms/step - loss: 0.0684 - acc: 0.9755 - val_loss: 0.2282 - val_acc: 0.9393\n",
      "Epoch 5/10\n",
      "603/603 [==============================] - 70s 116ms/step - loss: 0.1708 - acc: 0.9777 - val_loss: 0.2803 - val_acc: 0.9318\n",
      "Epoch 6/10\n",
      "603/603 [==============================] - 71s 118ms/step - loss: 0.0240 - acc: 0.9922 - val_loss: 0.3185 - val_acc: 0.9342\n",
      "Epoch 7/10\n",
      "603/603 [==============================] - 72s 119ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.4333 - val_acc: 0.9325\n",
      "Epoch 8/10\n",
      "603/603 [==============================] - 71s 118ms/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.3933 - val_acc: 0.9311\n",
      "Epoch 9/10\n",
      "603/603 [==============================] - 71s 119ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.4772 - val_acc: 0.9332\n",
      "Epoch 10/10\n",
      "603/603 [==============================] - 71s 118ms/step - loss: 0.0134 - acc: 0.9954 - val_loss: 0.4288 - val_acc: 0.9311\n"
     ]
    }
   ],
   "source": [
    "history_log=model3.fit(rgersh_train, reg_train_label, epochs=10,verbose=1,validation_data=(rgersh_val, reg_val_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db1a2c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 2s 16ms/step - loss: 0.4926 - acc: 0.9260\n",
      " Model loss on the test set: 0.4926230013370514\n",
      " Model accuracy on the test set: 92.59796738624573\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model3.evaluate(rgersh_test, reg_test_label)\n",
    "print(f' Model loss on the test set: {loss}')\n",
    "print(f' Model accuracy on the test set: {100*accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "994f96a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 2s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model3.predict(rgersh_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abb59028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf_matrix_2.0_70\n",
      "\n",
      "[[1939  119]\n",
      " [ 187 1889]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(reg_test_label,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f134881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9a4c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.59796806966618\n",
      "92.59688510682925\n",
      "92.59796806966618\n",
      "92.6451694447621\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(reg_test_label, pred_arg)*100)\n",
    "print(f1_score(reg_test_label,pred_arg,average='macro')*100)\n",
    "print(recall_score(reg_test_label, pred_arg, average=\"weighted\")*100)\n",
    "print(precision_score(reg_test_label, pred_arg, average=\"weighted\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1ecde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805443b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
