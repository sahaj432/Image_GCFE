{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d67456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 12:37:22.715310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-09 12:37:24.975005: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-09 12:37:26.436978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-09 12:37:26.437045: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-09 12:37:38.773593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-09 12:37:38.773697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-09 12:37:38.773706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from image_graph_util import img_conversion_v7\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from emnist import extract_training_samples,extract_test_samples\n",
    "from emnist import list_datasets\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e174353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34e611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img_conversion_v7.image_convert()\n",
    "\n",
    "patch=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f1f33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']\n"
     ]
    }
   ],
   "source": [
    "print(list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9547fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images,train_labels=extract_training_samples('balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec54ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = extract_test_samples('balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951b5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of train dataset\n",
    "ftrain_images = np.float16(np.array(train_images)/255)\n",
    "train_labels = np.float16(np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6371893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of test dataset\n",
    "ftest_images = np.float16(np.array(test_images)/255)\n",
    "test_labels = np.float16(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ccca09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 28, 28)\n",
      "(18800, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(ftrain_images.shape)\n",
    "print(ftest_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451629f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making 28,28,1\n",
    "rtrain_images=ftrain_images.reshape(ftrain_images.shape[0],ftrain_images.shape[1],ftrain_images.shape[2],1)\n",
    "rtest_images=ftest_images.reshape(ftest_images.shape[0],ftest_images.shape[1],ftest_images.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184c03de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 28, 28, 1)\n",
      "(18800, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(rtrain_images.shape)\n",
    "print(rtest_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd49a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_val,reg_test,reg_val_label,reg_test_label=train_test_split(rtest_images,test_labels,test_size=0.50,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "548fdbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_train=rtrain_images\n",
    "reg_train_label=train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2010414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 28, 28, 1)\n",
      "(9400, 28, 28, 1)\n",
      "(9400, 28, 28, 1)\n",
      "(112800,)\n",
      "(9400,)\n",
      "(9400,)\n"
     ]
    }
   ],
   "source": [
    "print(reg_train.shape)\n",
    "print(reg_val.shape)\n",
    "print(reg_test.shape)\n",
    "print(reg_train_label.shape)\n",
    "print(reg_val_label.shape)\n",
    "print(reg_test_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3bf9131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 3000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 9441 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 15869 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 22093 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 28359 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 34620 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 41004 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 47438 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 53882 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 63595 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 72231 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 81138 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 89247 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 99592 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 108740 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 4454 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 3695 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ==> 9246 \r"
     ]
    }
   ],
   "source": [
    "reg_train_patch=img.to_patcharray(reg_train,patch_size=(patch,patch))\n",
    "reg_val_patch=img.to_patcharray(reg_val,patch_size=(patch,patch))\n",
    "reg_test_patch=img.to_patcharray(reg_test,patch_size=(patch,patch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2e37a",
   "metadata": {},
   "source": [
    "####  Patch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f845f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_train_patch.shape)\n",
    "print(reg_val_patch.shape)\n",
    "print(reg_test_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29beaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#print((Counter(y_val)))\n",
    "print(np.sort(list(Counter(reg_train_label).keys())))\n",
    "classes=len(np.sort(list(Counter(reg_train_label).keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b0cea",
   "metadata": {},
   "source": [
    "# Laplacian image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b8d0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def compute_grid_lap_channel(df_in): #compute_grid_lap_channel\n",
    "    g = nx.generators.lattice.grid_2d_graph(patch,patch, periodic=False)\n",
    "    adj_ary=nx.adjacency_matrix(g).toarray()\n",
    "\n",
    "    edge=np.array(np.where(adj_ary==1))\n",
    "    ed0=edge[0]\n",
    "    ed1=edge[1]\n",
    "\n",
    "    no_img,no_ch, no_patch,patch_x,patch_y=df_in.shape\n",
    "    temp=[]\n",
    "    for i in range(no_img):\n",
    "        i_ary = np.eye(patch_x*patch_y)\n",
    "        i_ary4d=i_ary[np.newaxis,np.newaxis,:,:]\n",
    "        weighted_adj=np.zeros((no_ch, no_patch,patch_x*patch_y,patch_x*patch_y))\n",
    "        df=df_in[i].reshape(no_ch,no_patch,-1)\n",
    "        pixel1=df[:,:,ed0]\n",
    "        pixel2=df[:,:,ed1]  \n",
    "        edu_distance=np.sqrt((pixel1-pixel2)**2)+ 10**(-8)\n",
    "        weighted_adj[:,:,ed0,ed1]=edu_distance\n",
    "        sum_r=np.sum(weighted_adj,axis=2)\n",
    "        temp_adj=sum_r[:,:,:,np.newaxis]\n",
    "        deg=temp_adj*i_ary4d\n",
    "        L=deg-weighted_adj\n",
    "        temp.append(L)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b82bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(\"Number of CPU cores:\", num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d889e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patch1=np.array_split(reg_train_patch[:], num_cores)\n",
    "val_patch1=np.array_split(reg_val_patch[:], num_cores)\n",
    "test_patch1=np.array_split(reg_test_patch[:], num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd53696",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_patch1))\n",
    "print(len(val_patch1))\n",
    "print(len(test_patch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcebb481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool:\n",
    "        # Define a list of numbers\n",
    "    train_p = train_patch1\n",
    "    \n",
    "        # Apply the square function to each number using the pool\n",
    "    g_train=pool.map(compute_grid_lap_channel,train_p)\n",
    "pool.close()\n",
    "\n",
    "\n",
    "    \n",
    "        #results = pool.map(calculate_visibility, numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca244dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=[]\n",
    "for submatrix in g_train:\n",
    "    temp1.extend(submatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d087f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gersh_train= np.array([np.asarray(submatrix) for submatrix in temp1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a03ea51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "print(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c43ee537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool1:\n",
    "        # Define a list of numbers\n",
    "    val_p = val_patch1\n",
    "    \n",
    "        # Apply the square function to each number using the pool\n",
    "    g_val=pool1.map(compute_grid_lap_channel,val_patch1)    \n",
    "pool1.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66c6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2=[]\n",
    "for submatrix in g_val:\n",
    "    temp2.extend(submatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8950a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gersh_val= np.array([np.asarray(submatrix) for submatrix in temp2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "915893f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "print(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e65520e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=num_cores) as pool2:\n",
    "        # Define a list of numbers\n",
    "    test_p = test_patch1\n",
    "    \n",
    "        # Apply the square function to each number using the pool\n",
    "    g_test=pool2.map(compute_grid_lap_channel,test_patch1) \n",
    "pool2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4128788",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3=[]\n",
    "for submatrix in g_test:\n",
    "    temp3.extend(submatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8083ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gersh_test= np.array([np.asarray(submatrix) for submatrix in temp3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b348698",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gersh_train=np.array(img1.to_gridlaparray(train_patch))\n",
    "gersh_val=np.array(img1.to_gridlaparray(val_patch))\n",
    "gersh_test=np.array(img1.to_gridlaparray(test_patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "089c2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 1, 49, 16, 16)\n",
      "(9400, 1, 49, 16, 16)\n",
      "(9400, 1, 49, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(gersh_train.shape)\n",
    "print(gersh_val.shape)\n",
    "print(gersh_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d8b310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_train=gersh_train\n",
    "lap_val=gersh_val\n",
    "lap_test=gersh_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd659e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 1, 49, 16, 16)\n",
      "(9400, 1, 49, 16, 16)\n",
      "(9400, 1, 49, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(lap_train.shape)\n",
    "print(lap_val.shape)\n",
    "print(lap_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2547201",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlap_train=np.moveaxis(lap_train,1,-1)\n",
    "rlap_val=np.moveaxis(lap_val,1,-1)\n",
    "rlap_test=np.moveaxis(lap_test,1,-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c401b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlap_train=rlap_train.reshape(rlap_train.shape[0],rlap_train.shape[1]*rlap_train.shape[2],rlap_train.shape[3],rlap_train.shape[4])\n",
    "rlap_val=rlap_val.reshape(rlap_val.shape[0],rlap_val.shape[1]*rlap_val.shape[2],rlap_val.shape[3],rlap_val.shape[4])\n",
    "rlap_test=rlap_test.reshape(rlap_test.shape[0],rlap_test.shape[1]*rlap_test.shape[2],rlap_test.shape[3],rlap_test.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54f358cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 784, 16, 1)\n",
      "(112800, 784, 16, 1)\n",
      "(112800, 784, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "print(rlap_train.shape)\n",
    "print(rlap_train.shape)\n",
    "print(rlap_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ccaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09033aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrlap_train=rlap_train.reshape(rlap_train.shape[0],-1)\n",
    "rrlap_val=rlap_val.reshape(rlap_val.shape[0],-1)\n",
    "rrlap_test=rlap_test.reshape(rlap_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a953be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 12544)\n",
      "(112800, 12544)\n",
      "(112800, 12544)\n"
     ]
    }
   ],
   "source": [
    "print(rrlap_train.shape)\n",
    "print(rrlap_train.shape)\n",
    "print(rrlap_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "826844b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L= np.concatenate((rrlap_train,rrlap_val,rrlap_test), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65a8b7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131600, 12544)\n"
     ]
    }
   ],
   "source": [
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7d34873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 54.39382553100586 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "import time\n",
    "# Assuming you have your flattened Laplacian matrix stored in a variable called flattened_laplacian_matrix\n",
    "# Assuming the original shape of the Laplacian matrix is (6000, 6000)\n",
    "\n",
    "#Reshape the flattened Laplacian matrix back to its original shape\n",
    "random_matrix = L\n",
    "subset_size = 12544  # Define the size of the subset\n",
    "subset_matrix = random_matrix[:12544, :]\n",
    "\n",
    "graph_laplacian= .5*(subset_matrix + subset_matrix.T)\n",
    "start=time.time()\n",
    "# Perform eigen-decomposition on the Laplacian matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(graph_laplacian)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors in ascending order\n",
    "sorted_indices = np.argsort(eigenvalues)\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Choose the desired number of dimensions for the embedding\n",
    "n_dimensions = 1568\n",
    "\n",
    "# Extract the first 'n_dimensions' eigenvectors\n",
    "embedding = sorted_eigenvectors[:, 1:n_dimensions+1]\n",
    "\n",
    "# Normalize the embedding\n",
    "embedding = embedding / np.linalg.norm(embedding, axis=1, keepdims=True)\n",
    "end=time.time()\n",
    "print(\"--- %s seconds ---\" % (end - start))\n",
    "\n",
    "# Alternatively, you can use the SpectralEmbedding class from Scikit-Learn\n",
    "# spectral_embedder = SpectralEmbedding(n_components=n_dimensions, affinity='precomputed')\n",
    "# embedding = spectral_embedder.fit_transform(laplacian_matrix)\n",
    "#embedding = embedding.numpy()\n",
    "\n",
    "# The 'embedding' variable now contains the low-dimensional representation of your data using Laplacian Eigenmap\n",
    "\n",
    "# Use the embedding for further analysis or visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db24b947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12544, 1568)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "921a78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data  = np.dot(random_matrix[:], embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b482e311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131600, 1568)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f378312",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=transformed_data[:rlap_train.shape[0]]\n",
    "x_val=transformed_data[rlap_train.shape[0]:(rlap_train.shape[0]+rlap_val.shape[0])]\n",
    "x_test=transformed_data[(rlap_train.shape[0]+rlap_val.shape[0]):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f621412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 1568)\n",
      "(9400, 1568)\n",
      "(9400, 1568)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5efbc7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 12:40:44.636261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2023-07-09 12:40:44.716532: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-09 12:40:44.716623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0152): /proc/driver/nvidia/version does not exist\n",
      "2023-07-09 12:40:44.798842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1],1)\n",
    "num_classes = classes\n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Conv1D(filters= 32, kernel_size=3, activation='relu',padding='same',input_shape= input_shape))\n",
    "model2.add(tf.keras.layers.AveragePooling1D())\n",
    "model2.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model2.add(tf.keras.layers.AveragePooling1D())\n",
    "model2.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n",
    "model2.add(tf.keras.layers.AveragePooling1D())\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dropout(0.1))\n",
    "model2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='SparseCategoricalCrossentropy', optimizer='Adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22cd2c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1568, 32)          128       \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 784, 32)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 784, 32)           3104      \n",
      "                                                                 \n",
      " average_pooling1d_1 (Averag  (None, 392, 32)          0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 392, 32)           3104      \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (None, 196, 32)          0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 47)                24111     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,504,879\n",
      "Trainable params: 3,504,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c42b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3525/3525 [==============================] - 39s 10ms/step - loss: 1.4427 - acc: 0.5655 - val_loss: 0.8537 - val_acc: 0.7290\n",
      "Epoch 2/10\n",
      "3525/3525 [==============================] - 36s 10ms/step - loss: 0.7476 - acc: 0.7512 - val_loss: 0.7609 - val_acc: 0.7543\n",
      "Epoch 3/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.6024 - acc: 0.7940 - val_loss: 0.7038 - val_acc: 0.7779\n",
      "Epoch 4/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.5114 - acc: 0.8200 - val_loss: 0.6975 - val_acc: 0.7822\n",
      "Epoch 5/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.4409 - acc: 0.8421 - val_loss: 0.7421 - val_acc: 0.7786\n",
      "Epoch 6/10\n",
      "3525/3525 [==============================] - 37s 11ms/step - loss: 0.3909 - acc: 0.8564 - val_loss: 0.7745 - val_acc: 0.7765\n",
      "Epoch 7/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.3483 - acc: 0.8696 - val_loss: 0.8012 - val_acc: 0.7748\n",
      "Epoch 8/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.3165 - acc: 0.8805 - val_loss: 0.8289 - val_acc: 0.7796\n",
      "Epoch 9/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.2899 - acc: 0.8898 - val_loss: 0.8623 - val_acc: 0.7733\n",
      "Epoch 10/10\n",
      "3525/3525 [==============================] - 37s 10ms/step - loss: 0.2676 - acc: 0.8988 - val_loss: 0.9015 - val_acc: 0.7640\n"
     ]
    }
   ],
   "source": [
    "history_log=model2.fit(x_train, reg_train_label, epochs=10,verbose=1,validation_data=(x_val, reg_val_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f91e3ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 1s 3ms/step - loss: 0.8926 - acc: 0.7633\n",
      " Model loss on the test set: 0.8925580978393555\n",
      " Model accuracy on the test set: 76.32978558540344\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(x_test, reg_test_label)\n",
    "print(f' Model loss on the test set: {loss}')\n",
    "print(f' Model accuracy on the test set: {100*accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5ceb4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model2.predict(x_test)\n",
    "pred_arg = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe4b2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf_matrix_2.0_70\n",
      "\n",
      "[[ 87   0   0 ...   0   0   0]\n",
      " [  0 113   1 ...   1   2   0]\n",
      " [  0   0 143 ...   2   0   0]\n",
      " ...\n",
      " [  1   0   5 ...  94   0   1]\n",
      " [  0   1   0 ...   0 189   1]\n",
      " [  0   1   0 ...   1   1 161]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(reg_test_label,pred_arg)\n",
    "print(\"cnf_matrix_2.0_70\")\n",
    "print(\"\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da91a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score,roc_auc_score,roc_curve,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faa0fdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7632978723404256\n",
      "0.7629352451861243\n",
      "0.7632978723404256\n",
      "0.7683625924014279\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(reg_test_label, pred_arg))\n",
    "print(f1_score(reg_test_label,pred_arg,average='macro'))\n",
    "print(recall_score(reg_test_label, pred_arg, average=\"weighted\"))\n",
    "print(precision_score(reg_test_label, pred_arg, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15935d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c716d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
